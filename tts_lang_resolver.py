from __future__ import annotations
import re
from typing import List, Tuple, Optional
from lang_config import LANG_NAMES

# ---------- Emoji patterns ----------
_CUSTOM_EMOJI_RE = re.compile(r"<a?:[A-Za-z0-9_~]+:[0-9]+>")  # <:name:id> / <a:name:id>
# Unicode emoji blocks (‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ: Symbols & Pictographs, Dingbats, Misc Symbols, Flags)
_UNICODE_EMOJI_RE = re.compile(
    "[\U0001F300-\U0001FAFF\U00002700-\U000027BF\U00002600-\U000026FF\U0001F1E6-\U0001F1FF]+",
    flags=re.UNICODE,
)

def strip_emojis_for_tts(s: str) -> str:
    """‡∏ï‡∏±‡∏î‡∏ó‡∏±‡πâ‡∏á custom ‡πÅ‡∏•‡∏∞ unicode emoji ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö TTS"""
    if not s:
        return ""
    s = _CUSTOM_EMOJI_RE.sub("", s)
    s = _UNICODE_EMOJI_RE.sub("", s)
    return s

def is_emoji_only(s: str) -> bool:
    """‡∏ï‡∏£‡∏ß‡∏à‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏µ‡πÅ‡∏ï‡πà‡∏≠‡∏µ‡πÇ‡∏°‡∏à‡∏¥/‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á/Zero-width ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô"""
    if not s:
        return False
    t = s.strip()
    if not t:
        return False
    no_emoji = strip_emojis_for_tts(t)
    no_emoji = re.sub(r"[\u200B-\u200D\uFEFF\s]+", "", no_emoji)
    return len(no_emoji) == 0


# ---------- Language helpers ----------
_LANG_PATTERN = re.compile(r"^[A-Za-z]{2,3}(?:-[A-Za-z]{2,3})?$")

def sanitize_requested_lang(req: str | None) -> str:
    """
    ‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏†‡∏≤‡∏©‡∏≤‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏™‡∏±‡πâ‡∏ô (xx ‡∏´‡∏£‡∏∑‡∏≠ xx-YY) ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
    ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà/‡∏ß‡πà‡∏≤‡∏á ‚Üí ‡∏Ñ‡∏∑‡∏ô 'auto'
    """
    if not isinstance(req, str):
        return "auto"
    req = req.strip()
    if not req or not _LANG_PATTERN.fullmatch(req):
        return "auto"
    return req

# gTTS languages (‡∏ö‡∏≤‡∏á‡∏≠‡∏±‡∏ô‡∏ï‡πâ‡∏≠‡∏á map)
_GTTs_NORMALIZE = {
    "zh": "zh-CN",
    "zh-cn": "zh-CN",
    "zh_CN": "zh-CN",
    "zh-TW": "zh-TW",
    "jp": "ja",
    "pt-br": "pt",
    "pt_BR": "pt",
}

def normalize_gtts_lang(code: str) -> tuple[str, str]:
    """
    ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÇ‡∏Ñ‡πâ‡∏î‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ö gTTS ‡πÑ‡∏î‡πâ
    ‡∏Ñ‡∏∑‡∏ô (gtts_key, display_code)
    - display_code ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö log ‡πÉ‡∏´‡πâ‡∏™‡∏ß‡∏¢
    """
    if not code:
        return "en", "en"
    key = code.strip()
    key_lower = key.lower()
    key = _GTTs_NORMALIZE.get(key_lower, key_lower)
    # ‡∏ö‡∏≤‡∏á‡∏Å‡∏£‡∏ì‡∏µ gTTS ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏® ‚Üí ‡∏•‡∏î‡∏£‡∏π‡∏õ‡πÄ‡∏´‡∏•‡∏∑‡∏≠ 2 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£
    if "-" in key and key not in ("zh-CN", "zh-TW"):
        key = key.split("-")[0]
    return key, key


# ---------- Per-part shaping ----------
def normalize_parts_shape(parts: List[Tuple[str, str]]) -> List[Tuple[str, str]]:
    fixed: List[Tuple[str, str]] = []
    for a, b in parts:
        t, lg = a, b

        # ‡πÄ‡∏î‡∏¥‡∏°: ‡∏™‡∏•‡∏±‡∏ö‡∏ñ‡πâ‡∏≤ b ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡πÇ‡∏Ñ‡πâ‡∏î‡∏†‡∏≤‡∏©‡∏≤ ‡πÅ‡∏ï‡πà a ‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏†‡∏≤‡∏©‡∏≤
        # ‡∏õ‡∏£‡∏±‡∏ö: "‡∏ñ‡πâ‡∏≤ b ‡πÄ‡∏õ‡πá‡∏ô 'auto' ‡∏´‡πâ‡∏≤‡∏°‡∏™‡∏•‡∏±‡∏ö" ‡∏Å‡∏±‡∏ô‡πÄ‡∏Ñ‡∏™ text ‡∏™‡∏±‡πâ‡∏ô ‡πÜ ‡πÄ‡∏ä‡πà‡∏ô "no", "it", "es" ‡∏Ø‡∏•‡∏Ø
        if (
            (not _LANG_PATTERN.fullmatch(b or "")) and
            _LANG_PATTERN.fullmatch((a or "").strip()) and
            (b or "").strip().lower() != "auto"         # << ‡πÄ‡∏û‡∏¥‡πà‡∏° guard ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ
        ):
            t, lg = b, a

        t = strip_emojis_for_tts(t or "").strip()
        lg = sanitize_requested_lang(lg or "auto")
        if t:
            fixed.append((t, lg))
    return fixed


# ---------- Language detection heuristics ----------
def _detect_script_fast_char(ch: str) -> str:
    """
    ‡πÄ‡∏î‡∏≤‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏ï‡πà‡∏≠ 1 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£: th/ja/ko/ru/en/number/other
    """
    cp = ord(ch)
    # Thai
    if 0x0E00 <= cp <= 0x0E7F:
        return "th"
    # Hiragana/Katakana/CJK
    if (0x3040 <= cp <= 0x30FF) or (0x4E00 <= cp <= 0x9FFF):
        return "ja"
    # Hangul
    if 0xAC00 <= cp <= 0xD7AF:
        return "ko"
    # Cyrillic
    if 0x0400 <= cp <= 0x04FF:
        return "ru"
    # Latin letters
    if (0x0041 <= cp <= 0x005A) or (0x0061 <= cp <= 0x007A):
        return "en"
    # Digits
    if 0x0030 <= cp <= 0x0039:
        return "number"
    return "other"

def _detect_script_fast(s: str) -> str:
    """‡πÄ‡∏î‡∏≤‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏Ñ‡∏£‡πà‡∏≤‡∏ß ‡πÜ ‡∏Ç‡∏≠‡∏á‡∏™‡∏ï‡∏£‡∏¥‡∏á: th/ja/ko/ru/en (fallback en)"""
    for ch in s:
        cat = _detect_script_fast_char(ch)
        if cat in {"th", "ja", "ko", "ru", "en"}:
            return cat
    return "en"

def resolve_tts_code(text: str, hint: str = "auto") -> str:
    """
    ‡πÄ‡∏î‡∏≤‡∏†‡∏≤‡∏©‡∏≤ TTS ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (‡∏´‡∏•‡∏±‡∏á‡∏ï‡∏±‡∏î emoji ‡πÅ‡∏•‡πâ‡∏ß) + hint ('auto' ‡∏´‡∏£‡∏∑‡∏≠‡πÇ‡∏Ñ‡πâ‡∏î‡∏†‡∏≤‡∏©‡∏≤)
    - ‡∏ñ‡πâ‡∏≤ hint ‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á ‚Üí ‡πÉ‡∏ä‡πâ‡πÄ‡∏•‡∏¢
    - ‡∏ñ‡πâ‡∏≤ 'auto' ‚Üí ‡πÄ‡∏î‡∏≤‡∏ï‡∏≤‡∏°‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå
    """
    h = sanitize_requested_lang(hint)
    if h != "auto":
        return h
    clean = strip_emojis_for_tts(text or "").strip()
    if not clean:
        return "en"
    script = _detect_script_fast(clean)
    if script == "ja":
        return "ja"
    if script == "th":
        return "th"
    if script == "ko":
        return "ko"
    if script == "ru":
        return "ru"
    return "en"

def _guess_latin_language_by_words(t: str) -> str | None:
    """
    heuristic ‡∏á‡πà‡∏≤‡∏¢ ‡πÜ ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏•‡∏∞‡∏ï‡∏¥‡∏ô:
    - ‡∏ñ‡πâ‡∏≤‡∏û‡∏ö‡∏Ñ‡∏≥‡∏ö‡∏≤‡∏á‡∏Ñ‡∏≥ ‚Üí ‡πÄ‡∏î‡∏≤ de/fr/es/it/pt
    """
    s = t.lower()
    # ‡πÄ‡∏¢‡∏≠‡∏£‡∏°‡∏±‡∏ô
    if re.search(r"\b(und|nicht|danke|nein|ja|ich|√ºber|stra√üe)\b", s):
        return "de"
    # ‡∏ù‡∏£‡∏±‡πà‡∏á‡πÄ‡∏®‡∏™
    if re.search(r"\b(et|merci|non|oui|je|vous|avec|√™tre)\b", s):
        return "fr"
    # ‡∏™‡πÄ‡∏õ‡∏ô/‡πÇ‡∏õ‡∏£‡∏ï‡∏∏‡πÄ‡∏Å‡∏™/‡∏≠‡∏¥‡∏ï‡∏≤‡∏•‡∏µ (‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ñ‡∏£‡πà‡∏≤‡∏ß ‡πÜ)
    if re.search(r"\b(gracias|hola|buenos|no|s√≠|por|favor)\b", s):
        return "es"
    if re.search(r"\b(obrigado|ol√°|n√£o|sim|por|favor)\b", s):
        return "pt"
    if re.search(r"\b(grazie|ciao|non|si|per|favore)\b", s):
        return "it"
    return None

def resolve_parts_for_tts(
    parts: List[Tuple[str, str]],
    preferred_lang: Optional[str] = None,   # üÜï ‡πÄ‡∏û‡∏¥‡πà‡∏° param
) -> List[Tuple[str, str]]:
    """
    ‡πÄ‡∏î‡∏≤‡∏†‡∏≤‡∏©‡∏≤‡∏£‡∏≤‡∏¢‡∏ó‡πà‡∏≠‡∏ô + normalize ‡πÇ‡∏Ñ‡πâ‡∏î‡πÉ‡∏´‡πâ gTTS ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ
    ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ preferred_lang ‡πÉ‡∏´‡πâ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏Å‡πà‡∏≠‡∏ô (‡∏ä‡∏ô‡∏∞ heuristic)
    """
    # üÜï short-circuit: ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏£‡∏∞‡∏ö‡∏∏‡∏†‡∏≤‡∏©‡∏≤‡∏°‡∏≤ ‚Üí ‡πÉ‡∏ä‡πâ‡∏ï‡∏≤‡∏°‡∏ô‡∏±‡πâ‡∏ô‡∏ó‡∏∏‡∏Å‡∏ó‡πà‡∏≠‡∏ô
    if preferred_lang and preferred_lang.lower() != "auto":
        gtts_key, display = normalize_gtts_lang(preferred_lang)
        return [(text, display) for text, _ in normalize_parts_shape(parts)]

    out: List[Tuple[str, str]] = []
    for text, lg in normalize_parts_shape(parts):
        code = resolve_tts_code(text, lg)

        # fine tune ‡∏•‡∏∞‡∏ï‡∏¥‡∏ô‡∏´‡∏ô‡πà‡∏≠‡∏¢
        if code == "en":
            maybe = _guess_latin_language_by_words(text)
            if maybe:
                code = maybe

        # ‡πÄ‡∏î‡∏¥‡∏°: CJK ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Æ‡∏¥‡∏£‡∏∞/‡∏Ñ‡∏∞‡∏ï‡∏∞ ‚Üí ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö zh-CN
        if code in ("ja", "en"):
            has_hira_kata = bool(re.search(r"[\u3040-\u30FF]", text))
            has_cjk = bool(re.search(r"[\u4E00-\u9FFF]", text))
            if has_cjk and not has_hira_kata:
                code = "zh-CN"

        gtts_key, display = normalize_gtts_lang(code)
        out.append((text, display))
    return out


# ---------- Text segmentation & merging (moved from bot.py) ----------
def split_text_by_script(text: str) -> List[Tuple[str, str]]:
    """
    ‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏¥‡πâ‡∏ô ‡πÜ ‡∏ï‡∏≤‡∏°‡∏ä‡∏ô‡∏¥‡∏î‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå (‡πÑ‡∏ó‡∏¢/‡∏ç‡∏µ‡πà‡∏õ‡∏∏‡πà‡∏ô/‡∏Ø‡∏•‡∏Ø) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÉ‡∏ô TTS
    - ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡∏ö‡∏•‡πá‡∏≠‡∏Å‡πÉ‡∏´‡∏°‡πà‡∏à‡∏∞‡∏ñ‡∏∑‡∏≠‡πÄ‡∏õ‡πá‡∏ô 'th' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡πà‡∏≤‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏Å‡∏±‡∏ö‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÑ‡∏ó‡∏¢‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô
    """
    parts: List[Tuple[str, str]] = []
    current, current_lang = "", None

    for ch in text or "":
        ch_lang = _detect_script_fast_char(ch)

        if ch_lang == "number":
            if current_lang:
                # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏ö‡∏•‡πá‡∏≠‡∏Å‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß ‡πÉ‡∏´‡πâ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ï‡∏≤‡∏°‡∏ö‡∏•‡πá‡∏≠‡∏Å‡πÄ‡∏î‡∏¥‡∏°
                current += ch
            else:
                # ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏†‡∏≤‡∏©‡∏≤ ‡∏ï‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ó‡∏¢‡∏Å‡πà‡∏≠‡∏ô (‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏•‡∏Ç‡πÑ‡∏ó‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥)
                if current:
                    parts.append((current, current_lang or "th"))
                current, current_lang = ch, "th"
            continue

        if ch_lang == current_lang:
            current += ch
        else:
            if current:
                parts.append((current, current_lang or "th"))
            current, current_lang = ch, ch_lang

    if current:
        parts.append((current, current_lang or "th"))
    return parts

def merge_adjacent_parts(parts: List[Tuple[str, str]]) -> List[Tuple[str, str]]:
    """
    ‡∏£‡∏ß‡∏°‡∏ä‡∏¥‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏¥‡∏î‡∏Å‡∏±‡∏ô‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏ä‡∏ô‡∏¥‡∏î‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô
    - ‡∏Å‡∏£‡∏ì‡∏µ‡∏û‡∏¥‡πÄ‡∏®‡∏©: ‡∏ç‡∏µ‡πà‡∏õ‡∏∏‡πà‡∏ô + ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏™‡∏±‡πâ‡∏ô ‡πÜ ‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© ‡πÉ‡∏´‡πâ‡∏£‡∏ß‡∏°‡πÄ‡∏Ç‡πâ‡∏≤ ja (‡πÄ‡∏ä‡πà‡∏ô „Äú„Åß„Åôyo, „Åã„ÇèE)
    """
    merged: List[Tuple[str, str]] = []
    for text, lang in parts:
        if merged:
            last_text, last_lang = merged[-1]
            if lang == last_lang:
                merged[-1] = (last_text + text, lang)
                continue
            if last_lang == "ja" and lang == "en" and re.fullmatch(r"[A-Za-z0-9]{1,3}", text):
                merged[-1] = (last_text + text, "ja")
                continue
        merged.append((text, lang))
    return merged


# ---------- Cleaning translated text (moved from bot.py) ----------
def clean_translation(src_text: str, translated: str) -> str:
    """
    ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏õ‡∏•‡∏•‡πâ‡∏ß‡∏ô ‡πÜ
    - ‡∏•‡∏ö‡∏õ‡πâ‡∏≤‡∏¢‡∏Å‡∏≥‡∏Å‡∏±‡∏ö/echo/quote/‡∏ß‡∏á‡πÄ‡∏•‡πá‡∏ö/‡πÇ‡∏Ñ‡πâ‡∏î‡∏ö‡∏•‡πá‡∏≠‡∏Å ‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢
    """
    t = (translated or "").strip()
    # ‡∏ï‡∏±‡∏î‡∏´‡∏±‡∏ß‡∏õ‡πâ‡∏≤‡∏¢‡∏ö‡πà‡∏≠‡∏¢ ‡πÜ
    t = re.sub(r'^(‡πÅ‡∏õ‡∏•‡∏ß‡πà‡∏≤|‡∏Ñ‡∏≥‡πÅ‡∏õ‡∏•‡∏Ñ‡∏∑‡∏≠|‡∏´‡∏°‡∏≤‡∏¢‡∏ñ‡∏∂‡∏á|‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢)\s*[:Ôºö-]?\s*', '', t, flags=re.I)
    t = re.sub(r'^(Thai|TH|English|EN|Japanese|JA|Chinese|ZH|Korean|KO|Russian|RU|Vietnamese|VI)\s*[:Ôºö-]\s*', '', t, flags=re.I)
    # ‡∏ï‡∏±‡∏î‡∏Å‡∏≤‡∏£ echo ‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
    src = (src_text or "").strip()
    if src:
        t = re.sub(rf'^{re.escape(src)}\s*[:Ôºö-]?\s*', '', t, flags=re.I)
    # ‡∏•‡∏≠‡∏Å wrapper
    t = re.sub(r'^[\"\'`¬´\(\[]\s*', '', t)
    t = re.sub(r'\s*[\"\'`¬ª\)\]]$', '', t)
    # ‡∏õ‡πâ‡∏≤‡∏¢‡∏ß‡∏á‡πÄ‡∏•‡πá‡∏ö‡∏™‡∏±‡πâ‡∏ô ‡πÜ
    t = re.sub(r'^\((?:[^()]{1,60})\)\s*', '', t).strip()
    # ‡∏ï‡∏±‡∏î code fences ‡∏ó‡∏µ‡πà‡∏´‡∏•‡∏á‡∏°‡∏≤
    t = re.sub(r"^```.*?\n", "", t, flags=re.S).strip()
    t = re.sub(r"\n```$", "", t, flags=re.S).strip()
    return t

def safe_detect(text: str) -> str:
    """
    ‡∏ï‡∏£‡∏ß‡∏à‡∏†‡∏≤‡∏©‡∏≤‡πÅ‡∏ö‡∏ö hybrid:
    - ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡πÉ‡∏ä‡πâ langdetect ‡∏Å‡πà‡∏≠‡∏ô
    - ‡∏ñ‡πâ‡∏≤ detect ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ/‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö ‚Üí ‡πÉ‡∏ä‡πâ heuristic ‡∏à‡∏≤‡∏Å‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå
    - fallback ‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡πâ‡∏ô‡∏°‡∏≤‡∏Å
    """
    txt = (text or "").strip()
    if not txt:
        return "auto"

    if len(txt) <= 3 and re.fullmatch(r"[A-Za-z]+", txt):
        return "en"

    try:
        from langdetect import detect
        d = detect(txt)
    except Exception:
        d = "auto"

    if d not in LANG_NAMES:  # ‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏£‡∏≤
        # ‡πÉ‡∏ä‡πâ fast script detect
        script = _detect_script_fast(txt)
        return script if script in LANG_NAMES else "en"

    return d


# ---------- Public API ----------
__all__ = [
    # emoji / guard
    "strip_emojis_for_tts", "is_emoji_only",
    # lang codes
    "sanitize_requested_lang", "normalize_gtts_lang",
    # TTS resolving
    "normalize_parts_shape", "resolve_tts_code", "resolve_parts_for_tts",
    # segmentation / merging
    "split_text_by_script", "merge_adjacent_parts",
    # cleaning
    "clean_translation", "safe_detect",
]
